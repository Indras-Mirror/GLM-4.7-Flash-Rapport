# GLM-4.7-Flash-Rapport Environment Configuration
# Copy this file to ~/.glm-flash-env or add to your ~/.bashrc

# ============================================================================
# GLM-Flash Server Configuration
# ============================================================================

# Path to your GLM-4.7-Flash model directory (with llama.cpp)
export GLM_FLASH_SERVER_DIR="$HOME/AI/GLM-4.7-Flash-PRISM"

# Port for the local llama.cpp server
export GLM_FLASH_PORT="8082"

# Context size (tokens) - default 198000 for 24GB VRAM
export GLM_FLASH_CONTEXT_SIZE="198000"

# ============================================================================
# OpenRouter API (for vision/image analysis)
# ============================================================================

# Get your key at: https://openrouter.ai/
export OPENROUTER_API_KEY="sk-or-v1-your-key-here"

# Vision model to use (default: z-ai/glm-4.6v)
export OPENROUTER_MODEL="z-ai/glm-4.6v"

# ============================================================================
# Google Custom Search API
# ============================================================================

# Get your key at: https://console.cloud.google.com/
export GOOGLE_SEARCH_API_KEY="AIzaSy-your-key-here"

# Get your CX at: https://cse.google.com/
export GOOGLE_SEARCH_CX="your-custom-search-engine-id"

# ============================================================================
# Image Routing Proxy (optional)
# ============================================================================

# Port for the image routing proxy (default: 9101)
export IMAGE_ROUTING_PROXY_PORT="9101"

# ============================================================================
# Advanced Settings (optional)
# ============================================================================

# API timeout in milliseconds (default: 3000000 = 50 minutes)
export API_TIMEOUT_MS="3000000"
